# Reproduce GPT-2 (124M)

Reproduce the GPT-2 paper from scratch in torch. Make it compatible with ðŸ¤— Transformers.

**Paper**: [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

**Karpathy Video**: [Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU&ab_channel=AndrejKarpathy)