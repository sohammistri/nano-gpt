{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display, Markdown\n",
    "import tiktoken\n",
    "import wandb\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = os.listdir(\"../1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled\")\n",
    "test_files = os.listdir(\"../1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled\")\n",
    "\n",
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'news.en-00041-of-00100'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607716, 306688)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = [], []\n",
    "\n",
    "for train_file in train_files:\n",
    "    train_file_path = os.path.join(\"../1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled\", train_file)\n",
    "\n",
    "    with open(train_file_path) as file:\n",
    "        train_data_tmp = file.read().splitlines()\n",
    "        train_data.extend(train_data_tmp)\n",
    "\n",
    "for test_file in test_files:\n",
    "    test_file_path = os.path.join(\"../1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled\", test_file)\n",
    "\n",
    "    with open(test_file_path) as file:\n",
    "        test_data_tmp = file.read().splitlines()\n",
    "        test_data.extend(test_data_tmp)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607716, 306688)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [i.strip() for i in train_data]\n",
    "test_data = [i.strip() for i in test_data]\n",
    "train_data = [i for i in train_data if len(i) > 0]\n",
    "test_data = [i for i in test_data if len(i) > 0]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle this headlines and then join them\n",
    "random.seed(42)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24486172, 6121544)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.8\n",
    "split_idx = int(len(train_data) * split_ratio)\n",
    "val_data = train_data[split_idx:]\n",
    "train_data = train_data[:split_idx]\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3350678828, 837563352, 42010908)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_str = \"\\n\".join(train_data)\n",
    "val_str = \"\\n\".join(val_data)\n",
    "test_str = \"\\n\".join(test_data)\n",
    "\n",
    "len(train_str), len(val_str), len(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721763228, 180428249, 9050773)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = tokenizer.encode(train_str)\n",
    "val_tokens = tokenizer.encode(val_str)\n",
    "test_tokens = tokenizer.encode(test_str)\n",
    "\n",
    "len(train_tokens), len(val_tokens), len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911242250"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokens) + len(val_tokens) + len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../1-billion-word-language-modeling-benchmark-r13output/train.pkl', 'wb') as file:\n",
    "    pickle.dump(train_tokens, file)\n",
    "\n",
    "with open('../1-billion-word-language-modeling-benchmark-r13output/val.pkl', 'wb') as file:\n",
    "    pickle.dump(val_tokens, file)\n",
    "\n",
    "with open('../1-billion-word-language-modeling-benchmark-r13output/test.pkl', 'wb') as file:\n",
    "    pickle.dump(test_tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721763228, 180428249, 9050773)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read it back\n",
    "with open('../1-billion-word-language-modeling-benchmark-r13output/train.pkl', 'rb') as file:\n",
    "    train_tokens = pickle.load(file)\n",
    "\n",
    "with open('../1-billion-word-language-modeling-benchmark-r13output/val.pkl', 'rb') as file:\n",
    "    val_tokens = pickle.load(file)\n",
    "\n",
    "with open('../1-billion-word-language-modeling-benchmark-r13output/test.pkl', 'rb') as file:\n",
    "    test_tokens = pickle.load(file)\n",
    "\n",
    "len(train_tokens), len(val_tokens), len(test_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, emb_dim, block_size, n_heads, head_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        # 1st LayerNorm\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # first Linear to get from emb_dim --> 3 * n_heads*head_dim, to get k,q,v, then proj back to emb_dim\n",
    "        self.c_proj = nn.Linear(emb_dim, 3 * n_heads * head_dim, bias=False)\n",
    "        self.proj = nn.Linear(n_heads * head_dim, emb_dim)\n",
    "\n",
    "        # 2nd LayerNorm\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # finally thinking layer\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 4 * emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4 * emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # finally register the tril matrix\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get the shape\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # Layer norm\n",
    "        ln_x = self.ln1(x)\n",
    "\n",
    "        # Project and extract k,q,v\n",
    "        c = self.c_proj(ln_x) # (B,T,C)  --> (B,T,3*nh*H)\n",
    "        c = c.view(B, T, self.n_heads, 3 * self.head_dim) # (B,T,nh,3*H)\n",
    "        k, q, v = torch.split(c, self.head_dim, dim=-1) # each of shape B,T,nh,H\n",
    "        k, q, v = k.transpose(-3, -2), q.transpose(-3, -2), v.transpose(-3, -2) # B, nh, T, H\n",
    "\n",
    "        # Get the attention weights\n",
    "        wei = q @ k.transpose(-2, -1) * (self.head_dim**-0.50) # (B,nh,T,H) @ (B,nh,H,T) -> (B,nh,T,T)\n",
    "        wei = wei.masked_fill(self.mask[:, :, :T, :T] == 0, -float(\"inf\"))\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "        wei = self.dropout1(wei)\n",
    "\n",
    "        # Apply to v\n",
    "        act = wei @ v # (B,nh,T,T) @ (B,nh,T,H) -> (B,nh,T,H)\n",
    "        act = act.transpose(-3, -2) # B,T,nh,H\n",
    "        act = act.contiguous().view(B, T, self.n_heads * self.head_dim)\n",
    "\n",
    "        # Transform to emb_dim and skip connection\n",
    "        act = self.proj(act) # (B, T,C)\n",
    "        act = x + act\n",
    "\n",
    "        # Think and skip connections\n",
    "        ln_act = self.ln2(act)\n",
    "        out = self.ffn(ln_act) # (B,T,C)\n",
    "        out = x + out # x shape (B,T,C)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, emb_dim, n_layers, n_heads, head_dim, dropout, device):\n",
    "        super().__init__()\n",
    "\n",
    "        # helper variables\n",
    "        self.block_size = block_size\n",
    "        self.device = device\n",
    "\n",
    "        # Embedding lookup table\n",
    "        self.token_embbeding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, emb_dim)\n",
    "\n",
    "        # MHA head\n",
    "        self.MHA = nn.Sequential(*[MHA(emb_dim, block_size, n_heads, head_dim, dropout) for _ in range(n_layers)])\n",
    "\n",
    "        # Layernorm\n",
    "        self.ln = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # final linear layer\n",
    "        self.lm_layer = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "        # init weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        print(f\"Number of parameters: {sum([p.numel() for p in self.parameters()])}\")\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # x shape (B, T)\n",
    "        B, T = x.shape\n",
    "\n",
    "        token_emb = self.token_embbeding_table(x)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(0, T).to(self.device))\n",
    "        emb = token_emb + pos_emb\n",
    "\n",
    "        emb = self.MHA(emb)\n",
    "        emb = self.ln(emb)\n",
    "        logits = self.lm_layer(emb) # (B, T, V)\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, V = logits.shape\n",
    "            loss = F.cross_entropy(logits.view(B*T, V), targets.view(B*T))\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, max_tokens=1000):\n",
    "        with torch.no_grad():\n",
    "            cur_window, idx_list = torch.LongTensor([[0]]).to(self.device), [0] # (1, 1)\n",
    "\n",
    "            for i in range(max_tokens):\n",
    "                cur_window = cur_window[:, -self.block_size:] # (1, B)\n",
    "                logits, _ = self.forward(cur_window) # (1,B,V)\n",
    "                probs = torch.softmax(logits, dim=-1).squeeze(dim=0) # (B,V)\n",
    "                idx = torch.multinomial(probs, num_samples=1, replacement=True)[-1].item()\n",
    "                cur_window = torch.concat([cur_window, torch.LongTensor([[idx]]).view(1, 1).to(self.device)], dim=-1)\n",
    "                idx_list.append(idx)\n",
    "\n",
    "            generated_text = tokenizer.decode(idx_list)\n",
    "\n",
    "            return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(tokens, block_size, batch_size):\n",
    "    batch = torch.randint(0, len(tokens)-block_size, (batch_size,)) # B dimension array of random indices\n",
    "    Xb = torch.stack([torch.LongTensor(tokens[i:i+block_size]) for i in batch], dim=0) # Create (B, T) dimension array\n",
    "    yb = torch.stack([torch.LongTensor(tokens[i+1:i+block_size+1]) for i in batch], dim=0) # Create (B, T) dimension array\n",
    "    return Xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_loss(tokens, block_size, batch_size, model, device):\n",
    "    loss_values = []\n",
    "    for _ in range(100):\n",
    "        Xb, yb = get_batch(tokens, block_size, batch_size)\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        _, loss = model(Xb, yb)\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "    mean_loss = torch.FloatTensor(loss_values).mean().item()\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_tokens, val_tokens, model, optimizer, device, block_size, batch_size, n_iters, eval_interval):\n",
    "    train_lossi, val_lossi = [], []\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        model.train()\n",
    "        Xb, yb = get_batch(train_tokens, block_size, batch_size)\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        # forward\n",
    "        _, loss = model(Xb, yb)\n",
    "\n",
    "        # set grads to zero\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # do backward\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i % eval_interval == 0) or (i == n_iters - 1):\n",
    "            model.eval()\n",
    "            train_loss = compute_loss(train_tokens, block_size, batch_size, model, device)\n",
    "            val_loss = compute_loss(val_tokens, block_size, batch_size, model, device)\n",
    "\n",
    "            train_lossi.append(train_loss)\n",
    "            val_lossi.append(val_loss)\n",
    "            print(f\"Step {i:4d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "             # log metrics to wandb\n",
    "            # wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "        # break\n",
    "\n",
    "    return train_lossi, val_lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 128 # what is the maximum context length for predictions?\n",
    "n_iters = 5000\n",
    "eval_interval = n_iters//10\n",
    "lr = 3e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "emb_dim = 192\n",
    "n_heads = 6\n",
    "head_dim = emb_dim // n_heads\n",
    "n_layers = 3\n",
    "dropout = 0.2\n",
    "vocab_size = tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 20706769\n"
     ]
    }
   ],
   "source": [
    "model = NanoGPT(emb_dim=emb_dim, vocab_size=vocab_size, block_size=block_size, n_heads=n_heads,\\\n",
    "                 n_layers=n_layers, head_dim=head_dim, device=device, dropout=dropout)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0 | Train Loss: 10.6372 | Val Loss: 10.6377\n",
      "Step  500 | Train Loss: 6.0246 | Val Loss: 6.0152\n",
      "Step 1000 | Train Loss: 5.6117 | Val Loss: 5.6094\n",
      "Step 1500 | Train Loss: 5.3612 | Val Loss: 5.3678\n",
      "Step 2000 | Train Loss: 5.1962 | Val Loss: 5.2095\n",
      "Step 2500 | Train Loss: 5.0789 | Val Loss: 5.0804\n",
      "Step 3000 | Train Loss: 4.9879 | Val Loss: 4.9864\n",
      "Step 3500 | Train Loss: 4.9144 | Val Loss: 4.9170\n",
      "Step 4000 | Train Loss: 4.8485 | Val Loss: 4.8548\n",
      "Step 4500 | Train Loss: 4.8007 | Val Loss: 4.7980\n",
      "Step 4999 | Train Loss: 4.7613 | Val Loss: 4.7592\n"
     ]
    }
   ],
   "source": [
    "train_lossi, val_lossi = train(train_tokens=train_tokens, val_tokens=val_tokens, model=model, optimizer=optimizer,\\\n",
    "      device=device, block_size=block_size, batch_size=batch_size, n_iters=n_iters, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "! this year - and there will be .\n",
       "\n",
       "We 're keen to catch up with scuttles we play here in Sochi with some big games , \" said Professor Hudore , vice presidents of the statistical virtueside .\n",
       "\n",
       "\" We 're not quick hit my own first season at 200 the time .\n",
       "\n",
       "In the meantime , the bank could provide a $ 10 billion increase to a valuable $ 8m-a pound while Barclays had to reduce as a result in trading years on Sept .\n",
       "\n",
       "The successful seemingly ruined , at the Communist Party 5pp is near the same antiaogical symbol 's \" cloud of light-effectively self-ciplined \" revolution in flux .\n",
       "\n",
       "IF Ind .\n",
       "\n",
       "S Markets is established by CDSAI , which was posted in the Investor Relations online on heart failure at home to Cumbria landters , EC1 rans / enterprise by IBM & needs ( approximately 2 to 4.44 dollars ) , will represent the corporate legislature , including the Government 's state .\n",
       "\n",
       "The man may be seen as a smart ones from his normal life , arriving for a small to become a senior person .\n",
       "\n",
       "INMANYT : The ocrano Horse is one of the Fourth Leave Le Davis Cup of display , a \" English studio in the Olympic cricket , \" and a lion 's personality , an admire plastic Dutch icon , named Linda Sndy 's second -- followed a coin-like walk .\n",
       "\n",
       "I don 't have the president a piece of there via a complaint by irrigation services that g Hashumco , Jacques Nagija Panhandle Scotkagojans , an Marines divport specializing in art throughout the flight within Watchers .\n",
       "\n",
       "The reduction of those polled reduce its rating divided through the Annual Report on 718 million euros ( 97,000 REidders listed via a compensation exchange ) with the authorities , WSIFAA ( WHO ) .\n",
       "\n",
       "Lyllateovich and the Maxim magazine Hand Fort Worth ( A. Zhangande and Morgan Zhaapova compound dispat May 2005 , in June .\n",
       "\n",
       "\" If we put our aspirations at the meeting at the end of this country , the country is China has it , \" Mr Roberts said .\n",
       "\n",
       "But property sales at more public activity were purchase because it had also been be moved towards recession in 2011 by 2015 , according to Iranian-born U.S. Local Court .\n",
       "\n",
       "Just 3 percent of cases of homesteaders and mighty farmers go under the blink of a little complex .\n",
       "\n",
       "Edcio , a congressman and Didier Menz pulled out of the arm ?\n",
       "\n",
       "Joweiness and subscriber waals refusing a hearts by parents alike , the board finds a factor in that , as an explanation after the ceremony were destined for the struggles it had been .\n",
       "\n",
       "After allowing farewell to Menciers who tried to be one person on their differences -- were part of the book before the transport market , but not anyone in federal remotely-connected dolls by influential veteran designers .\n",
       "\n",
       "Our practice rates are muted by PGA 's current ratio must be the energy can be sent to Securities and Exchange Commission and the publisher .\n",
       "\n",
       "They and Basically thieves are forced to buy many authorities .\n",
       "\n",
       "But aimed at rush to pay overspersed under the inclined enjoyment of electrical conditions and gastroenter sauce orlees , perhaps in fine exchange than two leading whites .\n",
       "\n",
       "Carbon fell on each day after missed a bench at 18 by taking a 55-43 3-6 in the fourth centuries ago , his first record was 14-yard to win in the final 25 minutes left by 67 .\n",
       "\n",
       "So far , Posada or Milliter have two other groups above 500,000 more of the energy line of success , it saw its decision hike from the seizure of the rebuilding capacity to the flight collection .\n",
       "\n",
       "( AP ) - Rick Reynolds announced a baby-in-lawingel on Tuesday as he came defense party Superceived statewide in nine months but to raise her far to the second yard of a row -- not in Thailand .\n",
       "\n",
       "The latter was in 46 hospital during a year after hearing .\n",
       "\n",
       "This will hand runs a flash open game by posting the selfish spots .\n",
       "\n",
       "The US ambassador of the Eye Service ( AA ) allegedly found dead as the preception of a seizureogen of a resettlement tool in developing countries who have a cutcode on the sky. were also available to www.illcations / family insider .\n",
       "\n",
       "Or worth , more easily cluttered with tired fitness , so why will cause the sound with everyday frol tissue , but by mosterk cats : an economics of lifestyle and love ?\n",
       "\n",
       "( AP ) - incumbent Steve Smarter caught on the year in questionable brilliant Candne Brown took advantage within the Milwaukee Vikings to the top 11 victory over the season , he puts a three-game winning streak of a nine-game eighth wrist injury and disappeared in the third quarter .\n",
       "\n",
       "Two lines went on Sunday night and the bond scandal hurt by the San Francisco troops being crushed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt = \"\\n\\n\".join(model.generate().split(\"\\n\"))\n",
    "display(Markdown(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
