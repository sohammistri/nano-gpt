{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import load_config, call_with_matching_args, compute_loss, get_data\n",
    "from model import NanoGPT, MHA\n",
    "import tiktoken\n",
    "import math\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wandb_project': 'nano-gpt-token-tiny-shakespeare-large',\n",
       " 'batch_size': 128,\n",
       " 'block_size': 256,\n",
       " 'emb_dim': 384,\n",
       " 'n_heads': 6,\n",
       " 'head_dim': 64,\n",
       " 'n_layers': 6,\n",
       " 'dropout': 0.2,\n",
       " 'fixed_lr': False,\n",
       " 'n_iters': 4000,\n",
       " 'warmup_iters': 200,\n",
       " 'lr_decay_iters': 4000,\n",
       " 'learning_rate': 5e-05,\n",
       " 'min_lr': 5e-06,\n",
       " 'tokenizer_model': 'gpt-2',\n",
       " 'split_ratio': 0.8,\n",
       " 'checkpoint_dir': './checkpoint-tiny-shakespeare-scratch/',\n",
       " 'always_save_checkpoint': False,\n",
       " 'dataset': 'tiny_shakespeare',\n",
       " 'train_on_full': False,\n",
       " 'data_path': '../data/tiny-shakespeare/input.txt',\n",
       " 'continue_train': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = load_config(config_path=\"config-tiny-shakespeare-scratch.yml\")\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270420, 67605)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['device'] = torch.device(f\"cuda:0\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "tokenizer = tiktoken.encoding_for_model(CONFIG[\"tokenizer_model\"])\n",
    "CONFIG[\"vocab_size\"] = tokenizer.n_vocab\n",
    "CONFIG[\"tokenizer\"] = tokenizer\n",
    "train_tokens, val_tokens = call_with_matching_args(get_data, CONFIG)\n",
    "len(train_tokens), len(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_multiplier(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < CONFIG[\"warmup_iters\"]:\n",
    "        return (it + 1) / (CONFIG[\"warmup_iters\"] + 1)\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > CONFIG[\"lr_decay_iters\"]:\n",
    "        return CONFIG[\"min_lr\"] / CONFIG[\"learning_rate\"]\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - CONFIG[\"warmup_iters\"]) / (CONFIG[\"lr_decay_iters\"] - CONFIG[\"warmup_iters\"])\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return (CONFIG[\"min_lr\"] + coeff * (CONFIG[\"learning_rate\"] - CONFIG[\"min_lr\"])) / CONFIG[\"learning_rate\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny shakespeare from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 49386577\n"
     ]
    }
   ],
   "source": [
    "model1 = call_with_matching_args(NanoGPT, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3506/3126912265.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint1 = torch.load(\"best_tiny_shakespeare_ckpt.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'config'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint1 = torch.load(\"best_tiny_shakespeare_ckpt.pt\", map_location=\"cpu\")\n",
    "checkpoint1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
    "model1 = model1.to(CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.169842720031738"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(val_tokens, block_size=CONFIG[\"block_size\"], batch_size=CONFIG[\"batch_size\"],\\\n",
    "              model=model1, device=CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Lest thou doth cherish me more than read.\n",
       "\n",
       "ROMEO:\n",
       "No, as hurlABETH:\n",
       "And I a fatal rod of earnest,\n",
       "And any other mothers but true-fell Unloaded of my heart.\n",
       "\n",
       "CLAR LAURENCE:\n",
       "Poor crown? who breathed your father's womb,\n",
       "\n",
       "CLARENCE:Go, by, pral go with unfacheENCE:\n",
       "Madam.\n",
       "\n",
       "Let him is my children is contentmen.\n",
       "JOHN OF YORK:\n",
       "Uncle! God's speak now, nor the nature wisdom he stands in his land\n",
       "My lord.\n",
       "\n",
       "GLOUCESTER:\n",
       "O disin of thy understandingainer, look it is the king and I protest,\n",
       "I am once more to- login by the mind so.\n",
       "Hath, blessed land, take her state,\n",
       "You that's death like aly Hereford,\n",
       "Come, Boling clouds comes a king, but hard-day;\n",
       "And set for one another and to hold\n",
       "Those king's knees to have been in youth and the battle straight.\n",
       "Y ANNE:\n",
       "His sorrow hath outcry from the ground thy hand,\n",
       "He mayad! whose ancient fear the rest gives me,\n",
       "Your heart bekay to the king hath at my heart what?\n",
       "\n",
       "BUCKINGHAM:\n",
       "With blood he rather sleep, then, if he breathed all night,\n",
       "That you to catchly virtuous cord taunt and use consay,\n",
       "Love petition, which valiant millionsly queens,\n",
       "Give me my friend and sweet better that lodged in the leisurely hour\n",
       "Set up his liege,\n",
       "The stroke of France\n",
       "But letting fire affaced the sea\n",
       "Debleness ofholding up himself,\n",
       "For 'twould, for his new-pimei as that watch'd your city\n",
       "I'll meet,\n",
       "stridia unnecess them,\n",
       "Join'd with tears beam of visit home,\n",
       "That would dance.\n",
       "ROMEO:\n",
       "How now thou? frankly as since my Hereford?'\n",
       "\n",
       "ad! shed my mother, the loss hath brought away!\n",
       "\n",
       "AUFarewell cockly tale to death.\n",
       "Within the hands\n",
       "Stugg'd King Edward boy, this sword!\n",
       "When court in all whose kings'er:\n",
       "Which you much flat finger'd?\n",
       "To undeings hath assisted by heaven is can news to the wind that table.\n",
       "\n",
       "Nurse:\n",
       "I enter to him\n",
       "P depart and hand:\n",
       "Like an thrice by the melancholy lords, we would not my monastery the eyes?\n",
       "If now bey general hearing, shadows\n",
       "To barkearing whose princely father thus become meanspirator:\n",
       "About his eyes,\n",
       "That rend that he had spent into his subjects' glory in this royal part.\n",
       "\n",
       "WICK:\n",
       "Were in my brother and you flight,\n",
       "'Tis no more committed his bird age and perish be well reason in thy wretched tongue,\n",
       "That these misstones;\n",
       "Their foot of saints grandfather, brought this goose, bid him did I long as that foul way,\n",
       " Whole Lewiser could see him horse'll desire me\n",
       "Writ off their bark:\n",
       "But the feather.\n",
       "\n",
       "So encounter withalurments, if I fear;\n",
       "For this is my mother seems men warn offender with that is grew to mine hence.\n",
       "\n",
       "KING HENRY VI:\n",
       "The kinsmen were a man,\n",
       "And silver as it thus earlyravity limit thus a garhen'd\n",
       "And hoping the mid spring.\n",
       "\n",
       "EXET:\n",
       "they well-parted their honour the king,\n",
       "And, by depictionOUCESTER:\n",
       "With honour from your rights, and what is from your mother and duke.\n",
       "\n",
       "CLIFFORD:\n",
       "Come, Richard, peace braveamy to stock even to keep him from his most brotherCESTER:\n",
       "And weep.\n",
       "\n",
       " cry waste of his reasons you awhile.\n",
       "\n",
       "Second Lord herald in the gains nature, my dear comes your holy victory!\n",
       " and enduredARENCE:\n",
       "My lovely Richard, mine growth urged!\n",
       "My sovereign, that king, that has your dam\n",
       "Than to know not so:\n",
       "That, shall be his head did see his heirs at our made our face ancestry\n",
       "When any daughter and holy king and most bills\n",
       "On be stumbled; but come?\n",
       "Swell,; he, my lord, and let him will go Edward's headWe are in head.\n",
       "\n",
       "Shot from mine own sir, then;\n",
       "To bluntly?\n",
       "\n",
       "KING EDWARD IV:\n",
       "Of my lord;\n",
       "Now careful enemy as you lay upon the dearest, mark the ten traitor,\n",
       "With mine sufficient toius is the ground?\n",
       "\n",
       "GLOUCESTER:\n",
       "Of his love's lap, girls.\n",
       "How doth die.\n",
       "\n",
       "VIR"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(model1.generate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 49386577\n"
     ]
    }
   ],
   "source": [
    "model2 = call_with_matching_args(NanoGPT, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1562/3422859122.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint2 = torch.load(\"best-1B-pretrain-ckpt-1.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'config'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint2 = torch.load(\"best-1B-pretrain-ckpt-1.pt\", map_location=\"cpu\")\n",
    "checkpoint2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(checkpoint2['model_state_dict'])\n",
    "model2 = model2.to(CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.144304275512695"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(val_tokens, block_size=CONFIG[\"block_size\"], batch_size=CONFIG[\"batch_size\"],\\\n",
    "              model=model2, device=CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "! larvae grow rapidly here , \" said Dr Andrews .\n",
       "\n",
       "The States , which oversees the country 's largest nuclear watchdog , warned that the talks needed little chance of future negotiations .\n",
       "\n",
       "Rebounds _ New Orleans ( Hawaii ) ( 10 ) , second-highest conference scoring list ( in the West Region ) , 5 : 41 .\n",
       "\n",
       "\" Are the results , no , of course , that is accessibility , \" Mr Bush said , adding that the mission was meant to produce a video \" got back and forth \" and that was what he did to the surveillance programme .\n",
       "\n",
       "A further 11,000 people are returning .\n",
       "\n",
       "Hein says it is a campaign for that particular moral possibility .\n",
       "\n",
       "Anelka-district 106-5 passing pass gave Valles a 13-13 lead .\n",
       "\n",
       "Take a minute to get the ball .\n",
       "\n",
       "Tony Morales insists he is seeking more influence if the panoramic view comes from a deactivated single pesticide that causes cancer .\n",
       "\n",
       "We need no more than filmmakers , they say , colonies rely on a optimal view for arrogance .\n",
       "\n",
       "He said : \" Normally she died , her life had hit me .\n",
       "\n",
       "The television ad 's director , I.B. Mitchell , gave Wright O 'Donnell a look at Murtha 's remarks on June 14 when he ordered a interview on a video welcoming-mail more than 350 Web sites .\n",
       "\n",
       "( AP ) - Carolina State beat Kentucky to lift the Hornets 2-0 earlier this month , with a 3-2 victory for the White Sox .\n",
       "\n",
       "Enter Britain a \" safe haven \" for Abu Dhabi .\n",
       "\n",
       "\" What we may consider as a shock factor is that the Federal Reserve intends to regain compliance with federal funding restrictions that currently includes additional federal borrowing .\n",
       "\n",
       "His top six hit 6 1 / 3 shots in the first half as Georgia managed to become a firm tourist with a lethal dose in hand , but won safe .\n",
       "\n",
       "I have contacts with the filmmakers since 2004 and cannot remember how Murray grew up and left the show .\n",
       "\n",
       "The stars ' singles talent and their status relate to tourists .\n",
       "\n",
       "Lewis Perry 's Elizabeth Hall , who runs the airline , says it is time to wind up flights and stops working next week .\n",
       "\n",
       "Yyllands cavorted with Compassion in \" Slops Buzzoons , \" the way she did is up all this when you begin to see it backstage .\n",
       "\n",
       "I have interest in the yoga team , and the mine is a wise , caring place .\n",
       "\n",
       "The trip , which has been closed since the Gaza conflict , comes amid fears that North Korea has never vowed to resume permanently relaunch U.S. ties with the Iranian Taliban .\n",
       "\n",
       "Meanwhile , the youngest child of a human with a former university student from Poland said she would like to be interested in helping clients live in a British school .\n",
       "\n",
       "Wyke , winger David Robinson , 23 , and three other Spurs each had 2 points following the Chicago Blackhawks ' sloppy Mark Hughes rout of the San Diego Chargers on Friday night over a fourth straight season .\n",
       "\n",
       "As a writer ( who 's not a wealthy admirer of veteran journalist Bill Griffith , of Portsmouth provocateur Nigel Knigg company ) , Ms. Toniña hid an engine locked into the hallway of the building .\n",
       "\n",
       "Builds likely to rise beyond Mammoth Lakes during the second quarter , sending in items such as a great gnawe , a sign that big-box sales will be flowing with more orders from business owners .\n",
       "\n",
       "Like everyone at a party that 's laid off , he does .\n",
       "\n",
       "Without me purely competing in the Democratic Party , both the party and Democratic have never had subversion .\n",
       "\n",
       "The ship is the third of this ship buying its speedboats .\n",
       "\n",
       "Hughl Harper , 58 , already in his country for seeks , was caught blank after a drive-by Mr. Giuliani paid his campaign $ 10,000 wider than had planned , and claims he was trying to stabilize any country since 1992 .\n",
       "\n",
       "On her first visit in Normandy , Obama said the ability of the leadership to recognize Israel was likely by the same name as much Karl Rove as the permanent leader of the Hezbollah-led Respect Party .\n",
       "\n",
       "Murder , who has long been a pupil at Oxford and later now resides among the new parents of his relatives .\n",
       "\n",
       "The will at the Business Minister 's Mansion House , Select Committee Vice Chair Kelly Rowland said that it was important that ministers only want to know what they wanted .\n",
       "\n",
       "Still , some high-profile contenders this week have offered to return to the competition to compete in the North of Virginia on Wednesday to hammer out their first two ATP Tour meetings last week .\n",
       "\n",
       "Demonstrators scattered bundles of clothing , and they rolled stones at lean people while east of Baghdad .\n",
       "\n",
       "\" Since I moved from mass to rock music in the mid- of the 1990s , I have never been working as an engineer .\n",
       "\n",
       "What 's less have Mr McLaughlin standing in with a comrade ?\n",
       "\n",
       "If Cameroon 's"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt = model2.generate()\n",
    "\n",
    "display(Markdown(\"\\n\\n\".join(i for i in txt.split(\"\\n\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 49386577\n"
     ]
    }
   ],
   "source": [
    "model3 = call_with_matching_args(NanoGPT, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1562/3503268985.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint3 = torch.load(\"best-1B-pretrain-ckpt-2.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'config'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint3 = torch.load(\"best-1B-pretrain-ckpt-2.pt\", map_location=\"cpu\")\n",
    "checkpoint3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_state_dict(checkpoint3['model_state_dict'])\n",
    "model3 = model3.to(CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.111961364746094"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(val_tokens, block_size=CONFIG[\"block_size\"], batch_size=CONFIG[\"batch_size\"],\\\n",
    "              model=model3, device=CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "! Sam McLaughlin Group Co. of Spain .\n",
       "\n",
       "One of these things referred to the Company 's filings must send forward within a lengthy & markers ' assessment .\n",
       "\n",
       "If I were aware , I would be studying to show how much a boy would have to put a mini-ste ] back into seeptious privilege -- if I was overweight .\n",
       "\n",
       "Gifts are common , and rarely stopped .\n",
       "\n",
       "Moreover , so if China does not wish to confront its players ' concerns public about the incident , the MSM shouldn 't be buying the names of business activists -- as well as some potential witnesses who obtained their respective reports based on her personal plans .\n",
       "\n",
       "Jockey met with Brazilian Kim Chang in February last year for vice president Ava Keatingy .\n",
       "\n",
       "The counter-terrorism report sends a warning to the military to the downdiary to press the final government to sit down and talk about the companies .\n",
       "\n",
       "Madonna , a 52-year-old California man who became a steady-duty child last June with her children , took off nearby Staples Center Thursday and provides a nourishing expanse of art for men .\n",
       "\n",
       "Sen. Barack Obama , D-Ill . , and top Republican Edward B. Kennedy of Ohio were among 56 Republicans left critical of their proposed health bill , but had Republican Gov. Mike Huckabee 's campaign lost1-1 on the ballot .\n",
       "\n",
       "China is as big as it currently has in mainland Taiwan , says Queiroz Subichberg , assistant general director of the Amnesty International agency for Human Rights .\n",
       "\n",
       "And might agree it while it comes to Museum the Art of Philosophy and Culture , which holds the premiere of the event which has become the first terrestrial song of modern cinema ever produced for the past 16 years .\n",
       "\n",
       "The management required an an ATS to offer funds to Electronic Arts ' farm in Baltimore and Easton .\n",
       "\n",
       "Thanks to records released by Spectrum Partners , the agreement provides \" additional details \" being made in the trial court .\n",
       "\n",
       "( AP ) - Chris Jeffrey stepped onto the bench for the 61st minute Saturday with a clear fadeaway and positionbinding with a goal late in the second half to spark a 12-4 comeback and two assists .\n",
       "\n",
       "She won just about 40 minutes of fights with police who ended up on the inactive list , according to a list of two adults arrested in California .\n",
       "\n",
       "Perhaps the most poignant life of its man after exhausting death has become a one-dimensional companion .\n",
       "\n",
       "The passerby was attacked when the freight train got inside the ambulance and set up a Mercedes-Benz pickup truck near Kandahar province , Zimbabwe .\n",
       "\n",
       "Alongside Leicester 's Robben , 78 , had been fouled by three others having played hard nine times during a futtering run that left him blind .\n",
       "\n",
       "Kirk Macartney , 24 , a private equity specialist , said he understood the situation was \" extremely massive \" and some German manufacturers were doing no bad to slow the JGB deal and instead only wanted to stay afloat , while others end up working .\n",
       "\n",
       "Nokia , the world 's leading research company , Sarthen and the mobile maker is one of the favourites for the start of the year .\n",
       "\n",
       "The players were not just Barry Dameda ( played by Glenn Beck ) who sustained the worst-affected 2007 playoff spinner I 've ever seen since .\n",
       "\n",
       "It found at mixed last week that the markets were spared for the same period last year as it got up 0.4 % after plunging up 0.1 % on the fast-growing jump in sales of Nokia 's BlackBerry .\n",
       "\n",
       "That massive scramble for oil in neighboring China , the US and China are grounding 20 percent of the increase in energy costs , and increasing domestic demand should ease the impact of reckless consumption , says Robert Wagner of JPMorgan Multiple Resources. with its autos taskforce .\n",
       "\n",
       "A spokesman for Georgia 's Water Safety Force said there was no timetable to proceed .\n",
       "\n",
       "BT takes the position of director of the suit , which is due by June 17 .\n",
       "\n",
       "Congress would like to use a \" David Letterman \" programme to claw back 10 new presidential candidates , specifically known as \" Road by My Name , \" which he said \" I need young people as commanding in or when they try to and understand why government is coming from ! \"\n",
       "\n",
       "This year 's winner will be announced Tuesday by veteran Sondra , who has 23-year-old Danny Cusack , who will play his third Italian opponent in the final .\n",
       "\n",
       "At some point right , ... your tone resonates like that with Professor Mathis Watson stating it was cost up to the cover of mutual comments .\n",
       "\n",
       "Cook 's injury problems can only result by injury .\n",
       "\n",
       "A neighbor said the owner of his home , said she felt the infant well needs hospital treatment .\n",
       "\n",
       "But those feel confident about being a kid , chatting with freaks and working with him all over his mouth .\n",
       "\n",
       "The bank referred to a new concern to some investors , where mean coalition partners have moved into"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt = model3.generate()\n",
    "\n",
    "display(Markdown(\"\\n\\n\".join(i for i in txt.split(\"\\n\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuned model\n",
    "\n",
    "We use 2nd pretrained model since the starting val loss is a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 49386577\n"
     ]
    }
   ],
   "source": [
    "model4 = call_with_matching_args(NanoGPT, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3506/4051574032.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint4 = torch.load(\"best-tiny-shakespeare-ft.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'config'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint4 = torch.load(\"best-tiny-shakespeare-ft.pt\", map_location=\"cpu\")\n",
    "checkpoint4.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wandb_project': 'nano-gpt-token-tiny-shakespeare-finetune-large',\n",
       " 'batch_size': 256,\n",
       " 'block_size': 256,\n",
       " 'emb_dim': 384,\n",
       " 'n_heads': 6,\n",
       " 'head_dim': 64,\n",
       " 'n_layers': 6,\n",
       " 'dropout': 0.2,\n",
       " 'fixed_lr': False,\n",
       " 'n_iters': 1000,\n",
       " 'warmup_iters': 50,\n",
       " 'lr_decay_iters': 1000,\n",
       " 'learning_rate': 5e-05,\n",
       " 'min_lr': 5e-06,\n",
       " 'tokenizer_model': 'gpt-2',\n",
       " 'split_ratio': 0.8,\n",
       " 'checkpoint_dir': './checkpoint-tiny-shakespeare-finetune/',\n",
       " 'always_save_checkpoint': False,\n",
       " 'dataset': 'tiny_shakespeare',\n",
       " 'train_on_full': False,\n",
       " 'data_path': '../data/tiny-shakespeare/input.txt',\n",
       " 'continue_train': False,\n",
       " 'finetune': True,\n",
       " 'finetune_ckpt': 'best-1B-pretrain-ckpt-2.pt'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint4[\"config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.load_state_dict(checkpoint4['model_state_dict'])\n",
    "model4 = model4.to(CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.385370254516602"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(val_tokens, block_size=CONFIG[\"block_size\"], batch_size=CONFIG[\"batch_size\"],\\\n",
    "              model=model4, device=CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Clarence born worthy father; I hold you there:\n",
       "No longer require't.\n",
       "Our child's tears are smothered, I'll be his anchor.\n",
       "\n",
       "First Senator:\n",
       "He visits the sect.\n",
       "\n",
       "AUTOLYCUS0200:\n",
       "Our general 'sʼMost powerful news.\n",
       "\n",
       "MERCUTIO:\n",
       "For I come, my lord, whom Iseveral to't:\n",
       "If you see from winrée, you supplouch\n",
       "Some names upon your person therefore, though\n",
       "I offer any holy man to me;\n",
       "That I have wrought upon him as pitiful.\n",
       "\n",
       "ROMEO:\n",
       "Has it not been a theft, though still to suffer'd\n",
       "To cross his country or banish him all.\n",
       "Or, good Camillo,\n",
       "Not the humane morrow to be a foe,\n",
       "And I am redeem'd.\n",
       "\n",
       "Servant:\n",
       "What,\n",
       "Pray you, what, my lord? O downright is the voice of Greta's deadiscovery.\n",
       "\n",
       "VOLUMNIA:\n",
       "What, say you now?\n",
       "\n",
       "ROMEO:\n",
       "Away here! why, sir?\n",
       "\n",
       "BENVOLIO:\n",
       "Help not what?\n",
       "\n",
       "AUTOLYCUS:\n",
       "Well, let me grieve an hour without doubt,\n",
       "As I looked to sprinkle in my mouth at my mind.\n",
       "\n",
       "ROMEO:\n",
       "He does like a water-cold bale;\n",
       "But for an infraction, his bird's nose makes\n",
       "Dawn with Juliet, which all these about it;\n",
       "the duke hath been dreaded; because of his life,\n",
       "Nor my natural body.\n",
       "\n",
       "BRUTUS:\n",
       "Schrah, tell mehow than there is a danger?\n",
       "\n",
       "First Citizen:\n",
       "You are tender him, and therefore must be jest.\n",
       "\n",
       "ISABELLA:\n",
       "Ay, my Lord of Hereford, I pray Sandin hence.\n",
       "\n",
       "CAMILLO:\n",
       "O ay,\n",
       "Not so.\n",
       "\n",
       "MENENIUS:\n",
       "Come, tell me thisenance.\n",
       "\n",
       "MENENIUS:\n",
       "My mouth, thy pains may never be a shame to full,\n",
       "And sweetness in my life well,\n",
       "My patch is so virtuous as I gently do.\n",
       "\n",
       "Privy, I am reconciled and attentive,\n",
       "I thank you to your grave: I would rather conceive\n",
       "And know the model of the court to plot,\n",
       "I had rather do the honour burnt down\n",
       "Subscribed every ballad upon one side.\n",
       "\n",
       "CAMILLIUS:\n",
       "What! thou so?\n",
       "\n",
       "First Murderer:\n",
       "These newswells; they were dispersed, and\n",
       "Must cost some afoot. Therefore, he has no farther than his natural line\n",
       "moleslam'd himself, and he, in his sharp head,\n",
       "Dame not what Bolingbroke, dispatch'd from these men\n",
       "So if he should have made him apprentice: this is an example's\n",
       "or piercingly reachment alteration. I prithee, or else\n",
       "Of ordering him forth!\n",
       "\n",
       "MENENIUS:\n",
       "Besides, so early the sun\n",
       "Are you rich other appointments?\n",
       "\n",
       "SAMPSON:\n",
       "Soft:\n",
       "Sir. Tell me, what news?\n",
       "\n",
       "MENENIUS:\n",
       "Sir, crookens! methinks we demanded me think\n",
       "In Vienna when I had come home your young prince: now, i' the churchyard, there would be\n",
       "the prince that came from wife, play'd his character, when he fled;\n",
       "For, 'twixt with his brother.\n",
       "\n",
       "O, although he did, then in time to come but possess'd\n",
       "Of these whom did create thee, not his soul.\n",
       "\n",
       "PERDITA:\n",
       "Is him a gentleman, madam?\n",
       "\n",
       "MENENIUS:\n",
       "The principles he bids to wear the laws\n",
       "By circumstance dead deeds of young men?\n",
       "\n",
       "MENENIUS:\n",
       "Ay, my lord, and the true origin of rust,\n",
       "That counsels them\n",
       "If not, offer me a time to change their minds.\n",
       "\n",
       "MENENIUS:\n",
       "Yea, by this impudence thou shalt not see the instant of what's done.\n",
       "\n",
       "CORIOLANUS:\n",
       "I on a scale false, but call away\n",
       "These leery at night's point\n",
       "That none of us will, but we have record dudes.\n",
       "\n",
       "PAULINA:\n",
       "Obsessed the father, you have elgives private;\n",
       "Darwin, a brat for the dukesish age,\n",
       "For thee as this I have laid upon me,\n",
       "And thus did disguise myself.\n",
       "\n",
       "SICINIUS:\n",
       "I am000 to die; Come, go to bed:\n",
       "They have, but I will"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt = model4.generate()\n",
    "\n",
    "display(Markdown(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
